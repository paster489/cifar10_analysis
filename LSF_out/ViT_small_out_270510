loading ...
loaded conda.sh
sh shell detected
main => start
 
Datasets Load => start
 
Files already downloaded and verified
Files already downloaded and verified
Train/Validation random split => start
 
DataLoader => start
 
To_device => start
 
Train => start
 
Epoch [0], train_loss: 1.7502, train_acc: 0.3581, val_loss: 1.6772, val_acc: 0.3800
Epoch [1], train_loss: 1.7129, train_acc: 0.3641, val_loss: 1.6688, val_acc: 0.3857
Epoch [2], train_loss: 1.6537, train_acc: 0.3859, val_loss: 1.6463, val_acc: 0.3880
Epoch [3], train_loss: 1.6651, train_acc: 0.3855, val_loss: 1.6926, val_acc: 0.3700
Epoch [4], train_loss: 1.7005, train_acc: 0.3695, val_loss: 1.6713, val_acc: 0.3865
Epoch [5], train_loss: 1.6821, train_acc: 0.3772, val_loss: 1.6672, val_acc: 0.3903
Epoch [6], train_loss: 1.7901, train_acc: 0.3317, val_loss: 1.9148, val_acc: 0.2649
Epoch [7], train_loss: 1.8487, train_acc: 0.3037, val_loss: 1.8093, val_acc: 0.3223
Epoch [8], train_loss: 1.7825, train_acc: 0.3316, val_loss: 1.7511, val_acc: 0.3550
Epoch [9], train_loss: 1.7653, train_acc: 0.3435, val_loss: 1.7110, val_acc: 0.3651
Epoch [10], train_loss: 1.7825, train_acc: 0.3354, val_loss: 1.8075, val_acc: 0.3315
Epoch [11], train_loss: 1.8022, train_acc: 0.3230, val_loss: 1.7273, val_acc: 0.3664
Epoch [12], train_loss: 1.7621, train_acc: 0.3417, val_loss: 1.7283, val_acc: 0.3651
Epoch [13], train_loss: 1.7529, train_acc: 0.3509, val_loss: 1.7496, val_acc: 0.3613
Epoch [14], train_loss: 1.7401, train_acc: 0.3525, val_loss: 1.7463, val_acc: 0.3584
Epoch [15], train_loss: 1.7624, train_acc: 0.3420, val_loss: 1.7973, val_acc: 0.3359
Epoch [16], train_loss: 1.7541, train_acc: 0.3496, val_loss: 1.7167, val_acc: 0.3708
Epoch [17], train_loss: 1.7228, train_acc: 0.3608, val_loss: 1.6974, val_acc: 0.3714
Epoch [18], train_loss: 1.7194, train_acc: 0.3612, val_loss: 1.7096, val_acc: 0.3692
Epoch [19], train_loss: 1.7661, train_acc: 0.3429, val_loss: 1.7593, val_acc: 0.3366
Epoch [20], train_loss: 1.7640, train_acc: 0.3402, val_loss: 1.7354, val_acc: 0.3542
Epoch [21], train_loss: 1.7294, train_acc: 0.3542, val_loss: 1.6896, val_acc: 0.3637
Epoch [22], train_loss: 1.7008, train_acc: 0.3675, val_loss: 1.6954, val_acc: 0.3683
Epoch [23], train_loss: 1.6800, train_acc: 0.3776, val_loss: 1.6968, val_acc: 0.3725
Epoch [24], train_loss: 1.6768, train_acc: 0.3799, val_loss: 1.6821, val_acc: 0.3857
Epoch [25], train_loss: 1.6828, train_acc: 0.3786, val_loss: 1.6648, val_acc: 0.3959
Epoch [26], train_loss: 1.6646, train_acc: 0.3863, val_loss: 1.6632, val_acc: 0.3866
Epoch [27], train_loss: 1.6457, train_acc: 0.3933, val_loss: 1.6502, val_acc: 0.3992
Epoch [28], train_loss: 1.6398, train_acc: 0.3996, val_loss: 1.6471, val_acc: 0.3920
Epoch [29], train_loss: 1.6097, train_acc: 0.4104, val_loss: 1.5907, val_acc: 0.4213
Epoch [30], train_loss: 1.5924, train_acc: 0.4159, val_loss: 1.5675, val_acc: 0.4289
Epoch [31], train_loss: 1.5744, train_acc: 0.4235, val_loss: 1.5474, val_acc: 0.4371
Epoch [32], train_loss: 1.5511, train_acc: 0.4317, val_loss: 1.5644, val_acc: 0.4234
Epoch [33], train_loss: 1.5406, train_acc: 0.4346, val_loss: 1.5702, val_acc: 0.4223
Epoch [34], train_loss: 1.5238, train_acc: 0.4383, val_loss: 1.5147, val_acc: 0.4570
Epoch [35], train_loss: 1.5022, train_acc: 0.4499, val_loss: 1.5219, val_acc: 0.4503
Epoch [36], train_loss: 1.4954, train_acc: 0.4522, val_loss: 1.5152, val_acc: 0.4521
Epoch [37], train_loss: 1.4936, train_acc: 0.4505, val_loss: 1.4948, val_acc: 0.4646
Epoch [38], train_loss: 1.4761, train_acc: 0.4623, val_loss: 1.4783, val_acc: 0.4775
Epoch [39], train_loss: 1.4664, train_acc: 0.4633, val_loss: 1.5055, val_acc: 0.4635
Epoch [40], train_loss: 1.4502, train_acc: 0.4724, val_loss: 1.5010, val_acc: 0.4531
Epoch [41], train_loss: 1.4674, train_acc: 0.4577, val_loss: 1.4940, val_acc: 0.4625
Epoch [42], train_loss: 1.4776, train_acc: 0.4608, val_loss: 1.4842, val_acc: 0.4624
Epoch [43], train_loss: 1.4614, train_acc: 0.4650, val_loss: 1.4539, val_acc: 0.4724
Epoch [44], train_loss: 1.4320, train_acc: 0.4774, val_loss: 1.4637, val_acc: 0.4737
Epoch [45], train_loss: 1.4334, train_acc: 0.4743, val_loss: 1.4489, val_acc: 0.4799
Epoch [46], train_loss: 1.4140, train_acc: 0.4836, val_loss: 1.4263, val_acc: 0.4824
Epoch [47], train_loss: 1.3916, train_acc: 0.4915, val_loss: 1.4030, val_acc: 0.4913
Epoch [48], train_loss: 1.3806, train_acc: 0.4969, val_loss: 1.4208, val_acc: 0.4901
Epoch [49], train_loss: 1.3822, train_acc: 0.4985, val_loss: 1.4090, val_acc: 0.4941
Epoch [50], train_loss: 1.3706, train_acc: 0.5008, val_loss: 1.4016, val_acc: 0.4833
Epoch [51], train_loss: 1.3621, train_acc: 0.5057, val_loss: 1.4124, val_acc: 0.4971
Epoch [52], train_loss: 1.3520, train_acc: 0.5087, val_loss: 1.3668, val_acc: 0.5098
Epoch [53], train_loss: 1.3389, train_acc: 0.5099, val_loss: 1.3549, val_acc: 0.5057
Epoch [54], train_loss: 1.3311, train_acc: 0.5161, val_loss: 1.3719, val_acc: 0.5012
Epoch [55], train_loss: 1.3197, train_acc: 0.5217, val_loss: 1.3411, val_acc: 0.5127
Epoch [56], train_loss: 1.2937, train_acc: 0.5316, val_loss: 1.3543, val_acc: 0.5111
Epoch [57], train_loss: 1.2896, train_acc: 0.5328, val_loss: 1.3516, val_acc: 0.5216
Epoch [58], train_loss: 1.2736, train_acc: 0.5357, val_loss: 1.3302, val_acc: 0.5185
Epoch [59], train_loss: 1.2683, train_acc: 0.5384, val_loss: 1.3342, val_acc: 0.5181
Epoch [60], train_loss: 1.2511, train_acc: 0.5417, val_loss: 1.3080, val_acc: 0.5327
Epoch [61], train_loss: 1.2350, train_acc: 0.5482, val_loss: 1.3132, val_acc: 0.5304
Epoch [62], train_loss: 1.2237, train_acc: 0.5546, val_loss: 1.2976, val_acc: 0.5270
Epoch [63], train_loss: 1.2127, train_acc: 0.5602, val_loss: 1.3012, val_acc: 0.5302
Epoch [64], train_loss: 1.1878, train_acc: 0.5681, val_loss: 1.3287, val_acc: 0.5256
Epoch [65], train_loss: 1.1779, train_acc: 0.5735, val_loss: 1.2940, val_acc: 0.5395
Epoch [66], train_loss: 1.1628, train_acc: 0.5781, val_loss: 1.2672, val_acc: 0.5474
Epoch [67], train_loss: 1.1490, train_acc: 0.5827, val_loss: 1.2635, val_acc: 0.5413
Epoch [68], train_loss: 1.1201, train_acc: 0.5957, val_loss: 1.2674, val_acc: 0.5499
Epoch [69], train_loss: 1.0973, train_acc: 0.6042, val_loss: 1.2648, val_acc: 0.5570
Epoch [70], train_loss: 1.0817, train_acc: 0.6087, val_loss: 1.2722, val_acc: 0.5578
Epoch [71], train_loss: 1.0575, train_acc: 0.6139, val_loss: 1.2581, val_acc: 0.5489
Epoch [72], train_loss: 1.0314, train_acc: 0.6244, val_loss: 1.2476, val_acc: 0.5606
Epoch [73], train_loss: 0.9942, train_acc: 0.6371, val_loss: 1.2452, val_acc: 0.5619
Epoch [74], train_loss: 0.9632, train_acc: 0.6526, val_loss: 1.2823, val_acc: 0.5509
Epoch [75], train_loss: 0.9323, train_acc: 0.6621, val_loss: 1.2927, val_acc: 0.5565
Epoch [76], train_loss: 0.8904, train_acc: 0.6776, val_loss: 1.2482, val_acc: 0.5771
Epoch [77], train_loss: 0.8290, train_acc: 0.7002, val_loss: 1.3351, val_acc: 0.5658
Epoch [78], train_loss: 0.7742, train_acc: 0.7168, val_loss: 1.3623, val_acc: 0.5630
Epoch [79], train_loss: 0.7194, train_acc: 0.7381, val_loss: 1.3930, val_acc: 0.5673
Epoch [80], train_loss: 0.6539, train_acc: 0.7622, val_loss: 1.4662, val_acc: 0.5636
Epoch [81], train_loss: 0.6044, train_acc: 0.7772, val_loss: 1.4773, val_acc: 0.5552
Epoch [82], train_loss: 0.5486, train_acc: 0.7989, val_loss: 1.5906, val_acc: 0.5600
Epoch [83], train_loss: 0.5054, train_acc: 0.8172, val_loss: 1.7085, val_acc: 0.5579
Epoch [84], train_loss: 0.4641, train_acc: 0.8299, val_loss: 1.6726, val_acc: 0.5538
Epoch [85], train_loss: 0.4151, train_acc: 0.8491, val_loss: 1.7743, val_acc: 0.5615
Epoch [86], train_loss: 0.3782, train_acc: 0.8613, val_loss: 1.8647, val_acc: 0.5532
Epoch [87], train_loss: 0.3462, train_acc: 0.8742, val_loss: 1.9200, val_acc: 0.5531
Epoch [88], train_loss: 0.3067, train_acc: 0.8878, val_loss: 2.0473, val_acc: 0.5574
